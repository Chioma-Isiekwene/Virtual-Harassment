{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5984bf5",
   "metadata": {},
   "source": [
    "## Loading Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bca9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb94ea",
   "metadata": {},
   "source": [
    "### Kaggle Dynamically generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c58a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.read_csv('dynamical kaggle/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01296f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.concat(\n",
    "    [\n",
    "        kaggle[kaggle['label'] == 'hate'].sample(5000),\n",
    "        kaggle[kaggle['label'] == 'nothate'].sample(5000)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa92c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = kaggle.reset_index().drop('index',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021fe41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = kaggle[['text','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b11399",
   "metadata": {},
   "source": [
    "### Bayzick Bullying Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73c1f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet10Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet11Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet1Concensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet2Concensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet3Concensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet4Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet5Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet6Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet7Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet8Consensus.xlsx\n",
      "C:\\Users\\josh\\Documents\\work\\Cyber Bullying\\Cyber Bullying\\BayzickBullyingData\\Human Concensus\\Packet9Consensus.xlsx\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\josh\\\\Documents\\\\work\\\\Cyber Bullying\\\\Cyber Bullying\\\\BayzickBullyingData\"\n",
    "filenames = glob.glob(path + \"\\\\Human Concensus\\\\*.xlsx\")\n",
    "#print('File names:', filenames)\n",
    "b_labels = pd.DataFrame()\n",
    "for file in filenames:\n",
    "    print(file)\n",
    "    df = pd.concat(pd.read_excel(file, sheet_name=None, skiprows=2),ignore_index=True, sort=False)\n",
    "    b_labels = b_labels.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8038c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_labels.drop(['Unnamed: 2','Unnamed: 3'], inplace = True, axis = 1)\n",
    "b_labels.columns = ['filename', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f93876",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_labels.filename = b_labels.filename.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45bfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96cc882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadXML(p):\n",
    "    dirs = [x[0] for x in os.walk(p)]\n",
    "    data = []\n",
    "    for d in dirs[1:]:\n",
    "        filenames = glob.glob(d + \"\\*.xml\")\n",
    "        for file in filenames:\n",
    "            try:\n",
    "                #print(file)\n",
    "                tree = ET.parse(file)\n",
    "                f = file.split('\\\\')[-1].replace('.xml','')\n",
    "                root = tree.getroot()\n",
    "                texts = []\n",
    "                for post in root.findall(\".//post\"):\n",
    "                    for body in post.findall(\".//body\"):\n",
    "                        data.append([f,body.text])\n",
    "            except:\n",
    "                continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52a5527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_texts = loadXML(path+'\\\\packets\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a662383",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_texts = pd.DataFrame(b_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fcd8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_texts.columns = ['filename', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f318f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayzick = pd.merge(b_texts,b_labels, on = 'filename', how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38284c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayzick.dropna(inplace = True)\n",
    "bayzick.drop('filename', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04960f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayzick = bayzick.reset_index().drop('index',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e5a54",
   "metadata": {},
   "source": [
    "### Kaggle Youtube Parsed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88186992",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = pd.read_csv('various/youtube_parsed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e662f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.drop(['index', 'UserIndex', 'Number of Comments',\n",
    "       'Number of Subscribers', 'Membership Duration', 'Number of Uploads',\n",
    "       'Profanity in UserID', 'Age' ], axis = 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567380fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.columns = ['text',  'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c135296",
   "metadata": {},
   "source": [
    "### Kaggle Attack Parsed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cc0bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression = pd.read_csv('various/aggression_parsed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b3d44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression = pd.concat(\n",
    "    [\n",
    "        aggression[aggression['oh_label'] == 0].sample(5000),\n",
    "        aggression[aggression['oh_label'] == 1].sample(5000)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b95bc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression = aggression.reset_index().drop('index',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13495acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression.drop(['ed_label_0','ed_label_1', 'level_0'], axis = 1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "842d8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774c99f6",
   "metadata": {},
   "source": [
    "#  Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9b852bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'kaggle':kaggle, 'bayzick':bayzick, 'aggression':aggression, 'youtube':youtube}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece463ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012ba471",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13152\\2996534050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87962ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50cfbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Datasets\n",
    "for i, (n,df) in enumerate(datasets.items()):\n",
    "    df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "581abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2250b2",
   "metadata": {},
   "source": [
    "# Training and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a5c19",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f4691e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LR \n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier as NN\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GB\n",
    "from sklearn.ensemble import AdaBoostClassifier as AB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import VotingClassifier as VC\n",
    "import disarray as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_estimators = [\n",
    "    ('Naive Bayes', NB()),\n",
    "    ('K Nearest Neigbhor', KNN()),\n",
    "    ('Logistic Regression', LR()),\n",
    "    ('Decision Tree', DT()),\n",
    "    ('SVM', SVC()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42567428",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Naive Bayes': NB(),\n",
    "    'Random Forest': RFC(),\n",
    "    'K Nearest Neigbhor': KNN(),\n",
    "    'Logistic Regression': LR(),\n",
    "    'Decision Tree': DT(),\n",
    "    'SVM': SVC(),\n",
    "    'Neural Network': NN(),\n",
    "    'Gradient Boosting': GB(),\n",
    "    'Ada Boost': AB(),\n",
    "    'Quadratic Discriminant Analysis': QDA(),\n",
    "    'Max Voting': VC(estimators=voting_estimators, voting='hard')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaa6dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, cohen_kappa_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "756749da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classify(df, model):\n",
    "    x = df.drop([0,1],axis = 1)\n",
    "    y = df.iloc[:, 1]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.30, random_state = 42)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    ypred = model.predict(xtest)\n",
    "    accuracy = accuracy_score(ytest, ypred)\n",
    "    cls_report = classification_report(ytest,ypred)\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "\n",
    "    \n",
    "    return ytest, ypred, accuracy, cls_report, model, pd.DataFrame(cm, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "560993c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(df, models):\n",
    "    processed_text = preprocess.fit_transform(df.text).toarray()\n",
    "    df = pd.concat([df, pd.DataFrame(processed_text)],axis = 1, ignore_index = True)\n",
    "    results = {}\n",
    "    for i, (mn,model) in enumerate(models.items()):\n",
    "        print('Running '+mn)\n",
    "        ytest, ypred, accuracy, report, mod, cm = train_classify(df,model)\n",
    "        results[mn] = [ytest, ypred, accuracy, report, [mn,mod], cm]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(datasets, models):\n",
    "    experiment_results = {}\n",
    "    for i, (n,df) in enumerate(datasets.items()):\n",
    "        print('Running for: '+n)\n",
    "        results = run_models(df,models)\n",
    "        #experiment_results[n] = results\n",
    "    #return experiment_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df7c266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {'kaggle':datasets['kaggle']}\n",
    "b = {'bayzick':datasets['bayzick']}\n",
    "a = {'aggression':datasets['aggression']}\n",
    "y = {'youtube':datasets['youtube']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00319426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: kaggle\n",
      "Running Naive Bayes\n",
      "Running Random Forest\n",
      "Running K Nearest Neigbhor\n",
      "Running Logistic Regression\n",
      "Running Decision Tree\n",
      "Running SVM\n",
      "Running Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosting\n",
      "Running Ada Boost\n",
      "Running Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "#run models on kaggle dataset\n",
    "kag = run_experiments(k, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "841884e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: bayzick\n",
      "Running Naive Bayes\n",
      "Running Random Forest\n",
      "Running K Nearest Neigbhor\n",
      "Running Logistic Regression\n",
      "Running Decision Tree\n",
      "Running SVM\n",
      "Running Neural Network\n",
      "Running Gradient Boosting\n",
      "Running Ada Boost\n",
      "Running Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "#run models on bayzick dataset\n",
    "bay = run_experiments(b, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa5adfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for: aggression\n",
      "Running Naive Bayes\n",
      "Running Random Forest\n",
      "Running K Nearest Neigbhor\n",
      "Running Logistic Regression\n",
      "Running Decision Tree\n",
      "Running SVM\n",
      "Running Neural Network\n",
      "Running Gradient Boosting\n",
      "Running Ada Boost\n",
      "Running Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josh\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "#run models on aggression dataset\n",
    "agg = run_experiments(a, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cccbecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13152\\502404300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#run models on youtube dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myou\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'run_experiments' is not defined"
     ]
    }
   ],
   "source": [
    "#run models on youtube dataset\n",
    "you = run_experiments(y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529fd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels to numerical for result collation (AUC Function can only use numerical classes)\n",
    "def convertLabels(l, val, rep):\n",
    "    for i in l.keys():\n",
    "        l[i][0].replace(val,rep,inplace=True)\n",
    "        yp = l[i][1]\n",
    "        yp[yp == val] = rep\n",
    "        l[i][1] = yp\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d9336a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13152\\324519771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nothate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'N'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kag' is not defined"
     ]
    }
   ],
   "source": [
    "kag = convertLabels(kag, 'nothate', int(0)) \n",
    "kag = convertLabels(kag, 'hate', int(1))\n",
    "bay = convertLabels(bay, 'N', int(0)) \n",
    "bay = convertLabels(bay, 'Y', int(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e96c2",
   "metadata": {},
   "source": [
    "# Results and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a037eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collateResults(ytest,ypred, cm, model):\n",
    "    mcc = matthews_corrcoef(ytest, ypred)\n",
    "    kappa = cohen_kappa_score(ytest, ypred)\n",
    "    auc = roc_auc_score(ytest,ypred)\n",
    "    metrics = cm.da.export_metrics(metrics_to_include=[\n",
    "        'accuracy',\n",
    "        'f1',\n",
    "        'false_discovery_rate',\n",
    "        'false_negative_rate',\n",
    "        'false_positive_rate',\n",
    "        'negative_predictive_value',\n",
    "        'precision',\n",
    "        'recall',\n",
    "        'specificity',\n",
    "    ])[['micro-average']]\n",
    "    metrics.columns = model\n",
    "    metrics = metrics.transpose().reset_index()\n",
    "    metrics['MCC'] = [mcc]\n",
    "    metrics['KAPPA'] = [kappa]\n",
    "    metrics['AUC'] = [auc]\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855d82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(results):\n",
    "    res = {}\n",
    "    for i, (data,result) in enumerate(results.items()):\n",
    "        r = pd.DataFrame(columns=['index', 'accuracy', 'f1', 'false_discovery_rate',\n",
    "       'false_negative_rate', 'false_positive_rate',\n",
    "       'negative_predictive_value', 'precision', 'recall', 'specificity',\n",
    "       'MCC', 'KAPPA', 'AUC'])\n",
    "        for i, (model,performance) in enumerate(result.items()):\n",
    "            temp = collateResults(performance[0], performance[1].astype(float), performance[5], [model])\n",
    "            r = pd.concat([r,temp], ignore_index=True)\n",
    "        res[data] = r\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7965de08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13152\\1608956607.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'kaggle'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bayzick'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'aggression'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'youtube'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0myou\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'kag' is not defined"
     ]
    }
   ],
   "source": [
    "final_results = collate({'kaggle':kag,'bayzick':bay,'aggression':agg,'youtube':you})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ff878",
   "metadata": {},
   "source": [
    "### Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ee62f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_results.keys():\n",
    "    final_results[i].to_excel(i+'.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226b41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
